source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
ts
beta1
seBeta1
lm(y ~ x)
lm(y ~ x - 1)
cor(y, x) * sd(y) / sd(x)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
summary(fit)
?summary
?fit
?lm
fit$residuals
sd(fit$residuals)
summary(fit)
sd(fit$df.residual)
fit$df.residual
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
seBeta1
summary(fit)$sigma
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
fit
?geom_smooth
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata = newx, interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx, interval = "prediction"))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2) g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
g
dat
head(dat)
head(p1)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
mean(x)
?predict
predict(fit, mean(x))
length(x)
mean(x)
predict(fit, 3.21725)
fit <- lm(y ~ x)
data("mtcars")
y <- mtcars$mpg
x <- mtcars$wt
fit <- lm(y ~ x)
yEst <- predict(fit, mean(x)); yEst
predict(fit, 3.21725)
predict(fit, 1)
predict(fit)
predict(fit)predict(fit, data.frame(3.21725))
predict(fit, data.frame(3.21725))
fit
names(p1)
data.frame(predict(fit, newdata = 2, interval = "confidence"))
predict(fit, newdata = 3.21725)
predict(fit, newdata = 3.21725, interval = "prediction")
predict(fit, newdata = 3.21725, interval = ("prediction"))
predict(fit, newdata = 3.21725, interval = ("prediction"))
predict(fit, newdata = data.frame(3.21725), interval = ("prediction"))
fit
yEst <- fit$coefficients[1] + fit$coefficients[2] * mean(x); yEst
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
fit$coefficients
summary(fit)$coefficients
data("mtcars")
y <- mtcars$mpg
x <- mtcars$wt
fit <- lm(y ~ x)
yEst <- fit$coefficients[1] + fit$coefficients[2] * mean(x); yEst
# predict(fit, newdata = data.frame(3.21725), interval = ("prediction"))
sumCoef <- summary(fit)$coefficients
yEst <- fit$coefficients[1] + fit$coefficients[2] * mean(x); yEst
sumCoef <- summary(fit)$coefficients; sumCoef
fit$coefficients[1]
fit$coefficients[2]
qt(.975, df = fit$df)
fit$df
sumCoef[1] + qt(.975, df = fit$df) * sumCoef[1]) +
sumCoef[2] + qt(.975, df = fit$df) * sumCoef[2])
sumCoef[1] + qt(.975, df = fit$df) * sumCoef[1] +
sumCoef[2] + qt(.975, df = fit$df) * sumCoef[2]
sumCoef[1] + qt(.975, df = fit$df) * sumCoef[1] +
(sumCoef[2] + qt(.975, df = fit$df) * sumCoef[2]) * mean(x)
qt(.975, df = fit$df) * sumCoef[2])
qt(.975, df = fit$df) * sumCoef[2]
sumCoef[2]
sumCoef[1] + qt(.975, df = fit$df) * sumCoef[1]
sumCoef
sumCoef[1,1] + qt(.975, df = fit$df) * sumCoef[1,2] +
(sumCoef[2,1] * mean(x)) + qt(.975, df = fit$df) * sumCoef[2,2]
sumCoef[1,1] + qt(.975, df = fit$df) * sumCoef[1,2] +
(sumCoef[2,1] + qt(.975, df = fit$df) * sumCoef[2,2]) * mean(x)
sumCoef[1,1] - qt(.975, df = fit$df) * sumCoef[1,2] +
(sumCoef[2,1] - qt(.975, df = fit$df) * sumCoef[2,2]) * mean(x)
(sumCoef[1,1] - qt(.975, df = fit$df) * sumCoef[1,2]) +
(sumCoef[2,1] - qt(.975, df = fit$df) * sumCoef[2,2]) * mean(x)
(sumCoef[1,1] - qt(.975, df = fit$df) * sumCoef[1,2])
sumCoef[1,1]
(sumCoef[2,1] - qt(.975, df = fit$df) * sumCoef[2,2])
(sumCoef[1,1] - qt(.975, df = fit$df) * sumCoef[1,2]) +
(sumCoef[2,1] * mean(x)) - qt(.975, df = fit$df) * sumCoef[2,2]
sumCoef[1,1] + (sumCoef[2,1] * mean(x)) - qt(.975, df = fit$df) * sumCoef[2,2]
sumCoef[1,1] + (sumCoef[2,1] - qt(.975, df = fit$df) * sumCoef[2,2]) * mean(x)
yEst - qt(.975, df = fit$df) * sumCoef[2,2]
sumCoef
qt(.975, df = fit$df)
qt(.975, df = fit$df) * sumCoef[2,2]
?mtcars
x
mean(x)
yEst <- sumCoef[1] + sumCoef[2] * 3; yEst
# 95% upper confidence bound
yEst + qt(.975, df = fit$df) * sumCoef[2,2]
yEst + qt(.95, df = fit$df) * sumCoef[2,2]
yEst + qt(.9, df = fit$df) * sumCoef[2,2]
fit$df
qt(.975, df = fit$df)
yEst + qt(.975, df = 32) * sumCoef[2,2]
yEst
27.57 - 21.25
21.25 - 6.32
yEst + qt(.975, df = fit$df) * sumCoef[2,2] +
qt(.975, df = fit$df) * sumCoef[1,2]
data("mtcars")
y <- mtcars$mpg
x <- mtcars$wt
fit <- lm(y ~ x)
# predict(fit, newdata = data.frame(3.21725), interval = ("prediction"))
# yEst <- fit$coefficients[1] + fit$coefficients[2] * mean(x); yEst
sumCoef <- summary(fit)$coefficients; sumCoef
yEst <- sumCoef[1] + sumCoef[2] * mean(x); yEst
# 95% lower confidence bound
yEst - qt(.975, df = fit$df) * sumCoef[2,2] -
qt(.975, df = fit$df) * sumCoef[1,2]
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
yEst + qnorm(.975) * sumCoef[2,2] +
qnorm(.975) * sumCoef[1,2]
(sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]) / 2
sumCoef
yEst <- sumCoef[1,1] + sumCoef[2,1] * 3; yEst
yEst <- sumCoef[1,1] + sumCoef[2,1] * 3; yEst
# 95% upper confidence bound
yEst + qt(.975, df = fit$df) * sumCoef[2,2] +
qt(.975, df = fit$df) * sumCoef[1,2]
(sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]) * 2
sum(fit$residuals)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
yEst <- sumCoef[1,1] + sumCoef[2,1] * 3; yEst
sumCoef
?predict
yEst <- sumCoef[1,1] + sumCoef[2,1] * 3; yEst
# 95% upper confidence bound
yEst + qt(.975, df = fit$df) * sumCoef[2,2] +
qt(.975, df = fit$df) * sumCoef[1,2]
sumCoef[1,1]
qt(.975, df = fit$df) * sumCoef[1,2]
qt(.975, df = fit$df) * sumCoef[2,2]
yEst <- sumCoef[1,1] + sumCoef[2,1] * 3; yEst
# 95% upper confidence bound
yEst + qt(.975, df = fit$df) * sumCoef[2,2] * 3 +
qt(.975, df = fit$df) * sumCoef[1,2]
qt(.975, df = fit$df) * sumCoef[1,2]
27.57 - 28.51185
predict(fit, newdata = fata.frame(x = 3), interval = "confidence")
predict(fit, newdata = data.frame(x = 3), interval = "confidence")
fit
predict(fit, newdata = x = 3, interval = "confidence")
predict(fit, newdata = 3, interval = "confidence")
predict(fit, newdata = data.frame(x = 3), interval = "prediction")
predict(fit, newdata = data.frame(x = mean(x)), interval = "confidence")
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
sse <- summary(fit)$sigma
sqrt( sum(resid(fit)^2) / (n - 2) ); sigma
sse <- summary(fit)$sigma
sqrt( sum(resid(fit)^2) / (n - 2) )
sse
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
sse
sqrt( sum(resid(fit)^2) / (n - 2) )
sse <- summary(fit)$sigma
sqrt( sum(resid(fit)^2) / fit$df )
sse
x0 <- 3
yEst <- sumCoef[1,1] + sumCoef[2,1] * x0; yEst
# SOLUTION:
# 1) predict function
predict(fit, newdata = data.frame(x = x0), interval = "prediction")
# 2) manual (lecture 07-inference-regression)
sigma <- summary(fit)$sigma   # sqrt( sum(resid(fit)^2) / fit$df )
ssx <- sum((x - mean(x))^2)
# prediction interval se at x0
se <- sigma * sqrt(1 + 1/fit$df + (x0 - mean(x))^2 / ssx)
se
?qt
yEst + c(-1,1) * qt(0.975, df = fit$df) * se
sigma
sumCoef
# predict(fit, newdata = data.frame(3.21725), interval = ("prediction"))
# yEst <- fit$coefficients[1] + fit$coefficients[2] * mean(x); yEst
sumCoef <- summary(fit)$coefficients; sumCoef
x0 <- mean(x)
yEst <- sumCoef[1,1] + sumCoef[2,1] * x0; yEst
# # 95% lower confidence bound
# yEst - qt(.975, df = fit$df) * sumCoef[2,2] -
#     qt(.975, df = fit$df) * sumCoef[1,2]
# SOLUTION:
# 1) predict function
predict(fit, newdata = data.frame(x = x0), interval = "confidence")
# 2) manual (lecture 07-inference-regression)
sigma <- summary(fit)$sigma   # sqrt( sum(resid(fit)^2) / fit$df )
ssx <- sum((x - mean(x))^2)
# prediction interval se at x0
se <- sigma * sqrt(1/fit$df + (x0 - mean(x))^2 / ssx)
# prediction interval
yEst + c(-1,1) * qt(0.975, df = fit$df) * se
sqrt( sum(resid(fit)^2) / fit$df )
sigma
yEst + c(-1,1) * qt(0.95, df = fit$df) * se
yEst + c(-1,1) * qt(0.975, df = fit$df) * se
predict(fit, newdata = data.frame(x = x0), interval = "confidence")
fit$df
length(x)
yEst + c(-1,1) * qt(0.975, df = 32) * se
yEst + c(-1,1) * qt(0.975, df = fit$df) * se
sumCoef
predict(fit, newdata = data.frame(x = x0), interval = "confidence")
yEst + c(-1,1) * qt(0.975, df = fit$df) * se
yEst
# confidence interval se at x0
se <- sigma * sqrt(1/n + (x0 - mean(x))^2 / ssx)
# confidence interval
yEst + c(-1,1) * qt(0.975, df = fit$df) * se
yEst + c(-1,1) * qt(0.975, df = n) * se
yEst + c(-1,1) * qt(0.975, df = fit$df) * se
n
length(x)
data("mtcars")
y <- mtcars$mpg
x <- mtcars$wt
n <- length(x)
fit <- lm(y ~ x)
# predict(fit, newdata = data.frame(3.21725), interval = ("prediction"))
# yEst <- fit$coefficients[1] + fit$coefficients[2] * mean(x); yEst
sumCoef <- summary(fit)$coefficients; sumCoef
x0 <- mean(x)
yEst <- sumCoef[1,1] + sumCoef[2,1] * x0; yEst
# # 95% lower confidence bound
# yEst - qt(.975, df = fit$df) * sumCoef[2,2] -
#     qt(.975, df = fit$df) * sumCoef[1,2]
# SOLUTION:
# 1) predict function
predict(fit, newdata = data.frame(x = x0), interval = "confidence")
# 2) manual (lecture 07-inference-regression)
sigma <- summary(fit)$sigma   # sqrt( sum(resid(fit)^2) / fit$df )
ssx <- sum((x - mean(x))^2)
# confidence interval se at x0
se <- sigma * sqrt(1/n + (x0 - mean(x))^2 / ssx)
# confidence interval
yEst + c(-1,1) * qt(0.975, df = fit$df) * se
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
require(datasets); data(swiss); require(GGally); require(ggplot2)
g = ggpairs(swiss, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
summary(lm(Fertility ~ Agriculture, data = swiss))$coefficients
# Agriculture vs Fertility plot
source('~/Documents/01-coursera/01-data-science/07-regression/w1_quiz.R', echo=TRUE)
## Question 9
# Consider the data given by
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
# What value minimizes the sum of the squared distances between these points and itself?
w <- rep(1, length(x))
wlsq(x,w)
# Alternative:
lm(x ~ w - 1)
cor(x,w)
lm(x ~ rep(1, length(x)) - 1)
dot(x,w)
x*w
x %*% w
(x %*% w) / (x %*% x)
lm(x ~ w - 1)
(x %*% w)
w
x
sum(x)
(x %*% x)
length(x)
(x %*% w) / (w %*% w)
# Test variance equation for w (vector of all ones)
var_w <- 0
mn_w <- mean(w)
for (i in w) {
var_w <- var_w + (i - mn_w)^2
} var_w
w
var_w
mn_w
for (i in w) {
var_w <- var_w + (i - mn_w)^2
} var_w
i
(i in w)
for (i in w)
{i}
for (i in w) {}
for (i in w) { print(i) }
i = 1
var_w <- var_w + (i - mn_w)^2
for (i in w) {
var_w <- var_w + (i - mn_w)^2
} var_w
for (i in 1 : length(w)) {
var_w <- var_w + (i - mn_w)^2
} var_w
for (i in 1:10) {
print(i)
}
for (i in 1:length(w)) {
print(i)
}
for (i in 1:length(w)) {
print(i)
var_w <- var_w + (i - mn_w)^2
}
for (i in 1:length(w)) {
print(i)
var_w <- var_w + (i - mn_w)^2
} var_w
for (i in 1:length(w)) {
print(i)
var_w <- var_w + (i - mn_w)^2
}
var_w
# Test variance equation for w (vector of all ones)
var_w <- 0
mn_w <- mean(w)
for (i in 1 : length(w)) {
var_w <- var_w + (i - mn_w)^2
}
var_w
# Test variance equation for w (vector of all ones)
var_w <- 0
mn_w <- mean(w)
for (i in w) {
var_w <- var_w + (i - mn_w)^2
}
var_w
require(datasets); data(swiss); require(GGally); require(ggplot2)
g = ggpairs(swiss, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
summary(lm(Fertility ~ Agriculture, data = swiss))$coefficients
# Agriculture vs Fertility plot
str(swiss)
head(swiss)
fit <- lm(Fertility ~ Agriculture, data = swiss)
summary(fit)$coefficients
# Agriculture vs Fertility plot
x <- swiss$Agriculture
y <- swiss$Fertility
newx <- data.frame(x = seq(min(x), max(x), length = 100))
p1 <- data.frame(predict(fit, newdata = newx, interval = "confidence"))
p1$x = newx$x
names(p1)[1] <- "y"
g <- ggplot(p1, aes(x,y)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.2) +
geom_line() +
geom_point(data = data.frame(x=x, y=y), aes(x = x, y = y), size = 4)
g
fit <- lm(Fertility ~ Agriculture, data = swiss)
summary(fit)$coefficients
# Agriculture vs Fertility plot
x <- swiss$Agriculture
y <- swiss$Fertility
newx <- data.frame(x = seq(min(x), max(x), length = 100))
p1 <- data.frame(predict(fit, newdata = newx, interval = "confidence"))
p1$x = newx$x
names(p1)[1] <- "y"
g <- ggplot(p1, aes(x,y)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.2) +
geom_line() +
geom_point(data = data.frame(x=x, y=y), aes(x = x, y = y), size = 4)
g
fit <- lm(Fertility ~ Agriculture, data = swiss)
summary(fit)$coefficients
# Agriculture vs Fertility plot
x <- swiss$Agriculture
y <- swiss$Fertility
newx <- data.frame(x = seq(min(x), max(x), length = 100))
p1 <- data.frame(predict(fit, newdata = newx, interval = "confidence"))
p1$x = newx$x
names(p1)[1] <- "y"
g <- ggplot(p1, aes(x,y)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.2) +
geom_line() +
geom_point(data = data.frame(x=x, y=y), aes(x = x, y = y), size = 4)
g
newx <- data.frame(x = seq(min(x), max(x), length = 100))
p1 <- data.frame(predict(fit, newdata = newx, interval = "confidence"))
p1$x = newx$x
names(p1)[1] <- "y"
x
y
newx <- data.frame(x = seq(min(x), max(x), length = 100))
p1 <- data.frame(predict(fit, newdata = newx, interval = "confidence"))
fit
# Agriculture vs Fertility plot
x <- swiss$Agriculture
y <- swiss$Fertility
fit <- lm(y ~ x)
summary(fit)$coefficients
newx <- data.frame(x = seq(min(x), max(x), length = 100))
p1 <- data.frame(predict(fit, newdata = newx, interval = "confidence"))
p1$x = newx$x
names(p1)[1] <- "y"
g <- ggplot(p1, aes(x,y)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.2) +
geom_line() +
geom_point(data = data.frame(x=x, y=y), aes(x = x, y = y), size = 4)
g
summary(lm(Fertility ~ . , data = swiss))$coefficients
lm(Fertility ~ . , data = swiss)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
source('~/Documents/01-coursera/01-data-science/07-regression/w2_quiz.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
?InsectSprays
6.044761e-01
head(swiss)
hist(swiss$Catholic)
quantile(swiss$Catholic)
factor(CatholicBin))[1]
factor(CatholicBin)[1]
library(rgl)
plot3d(x1, x2, y)
install.packages("rgl")
library(rgl)
plot3d(x1, x2, y)
library(rgl)
install.package("rgl")
install.packages("rgl")
install.packages("rgl")
library(rgl)
plot3d(x1, x2, y)
hist(x2)
length(x2)
plot(x2
)
plot(1:n, x2)
plot(x1, x2)
plot(x2, x1)
p <- 0.5
n <- 100; x2 <- runif(n); x1 <- p * runif(n) - (1 - p) * x2
beta0 <- 0; beta1 <- 1; tau <- 4 ; sigma <- .01
y <- beta0 + x1 * beta1 + tau * x2 + rnorm(n, sd = sigma)
plot(x1, y, type = "n", frame = FALSE)
abline(lm(y ~ x1), lwd = 2)
co.pal <- heat.colors(n)
points(x1, y, pch = 21, col = "black", bg = co.pal[round((n - 1) * x2 + 1)], cex = 2)
plot(resid(lm(x1 ~ x2)), resid(lm(y ~ x2)), frame = FALSE, col = "black", bg = "lightblue", pch = 21, cex = 2)
abline(lm(I(resid(lm(x1 ~ x2))) ~ I(resid(lm(y ~ x2)))), lwd = 2)
p <- 0.1
n <- 100; x2 <- runif(n); x1 <- p * runif(n) - (1 - p) * x2
beta0 <- 0; beta1 <- 1; tau <- 4 ; sigma <- .01
y <- beta0 + x1 * beta1 + tau * x2 + rnorm(n, sd = sigma)
plot(x1, y, type = "n", frame = FALSE)
abline(lm(y ~ x1), lwd = 2)
co.pal <- heat.colors(n)
points(x1, y, pch = 21, col = "black", bg = co.pal[round((n - 1) * x2 + 1)], cex = 2)
p <- 0.0
n <- 100; x2 <- runif(n); x1 <- p * runif(n) - (1 - p) * x2
beta0 <- 0; beta1 <- 1; tau <- 4 ; sigma <- .01
y <- beta0 + x1 * beta1 + tau * x2 + rnorm(n, sd = sigma)
plot(x1, y, type = "n", frame = FALSE)
abline(lm(y ~ x1), lwd = 2)
co.pal <- heat.colors(n)
points(x1, y, pch = 21, col = "black", bg = co.pal[round((n - 1) * x2 + 1)], cex = 2)
plot(resid(lm(x1 ~ x2)), resid(lm(y ~ x2)), frame = FALSE, col = "black", bg = "lightblue", pch = 21, cex = 2)
abline(lm(I(resid(lm(x1 ~ x2))) ~ I(resid(lm(y ~ x2)))), lwd = 2)
p <- 0.1
n <- 100; x2 <- runif(n); x1 <- p * runif(n) - (1 - p) * x2
beta0 <- 0; beta1 <- 1; tau <- 4 ; sigma <- .01
y <- beta0 + x1 * beta1 + tau * x2 + rnorm(n, sd = sigma)
plot(x1, y, type = "n", frame = FALSE)
abline(lm(y ~ x1), lwd = 2)
co.pal <- heat.colors(n)
points(x1, y, pch = 21, col = "black", bg = co.pal[round((n - 1) * x2 + 1)], cex = 2)
plot(resid(lm(x1 ~ x2)), resid(lm(y ~ x2)), frame = FALSE, col = "black", bg = "lightblue", pch = 21, cex = 2)
abline(lm(I(resid(lm(x1 ~ x2))) ~ I(resid(lm(y ~ x2)))), lwd = 2)
plot(x2,x1)
?influence.measures
x <- c(10, rnorm(n)); y <- c(10, c(rnorm(n)))
plot(x, y, frame = FALSE, cex = 2, pch = 21, bg = "lightblue", col = "black")
abline(lm(y ~ x))
fit <- lm(y ~ x)
round(dfbetas(fit)[1 : 10, 2], 3)
round(hatvalues(fit)[1 : 10], 3)
dfbetas(fit)
hatvalues(fit)
